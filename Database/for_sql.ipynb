{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new database, new table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful!\n",
      "Database mt5_trade already exists.\n",
      "Table audusd_m15 checked and created if it did not exist.\n",
      "Database 'mt5_trade' and table 'audusd_m15' are connected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\trading-with-python\\Sen_trading\\Database\\helpers_database.py:126: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of rows from mt5:  6495\n",
      "Chunk 1 data imported successfully into audusd_m15!\n",
      "Chunk 2 data imported successfully into audusd_m15!\n",
      "Chunk 3 data imported successfully into audusd_m15!\n",
      "Chunk 4 data imported successfully into audusd_m15!\n",
      "Chunk 5 data imported successfully into audusd_m15!\n",
      "Chunk 6 data imported successfully into audusd_m15!\n",
      "Chunk 7 data imported successfully into audusd_m15!\n",
      "Data import completed successfully.\n"
     ]
    }
   ],
   "source": [
    "# region import\n",
    "import pyodbc\n",
    "import pandas as pd\n",
    "import MetaTrader5 as mt5\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from helpers_database import *\n",
    "# endregion\n",
    "\n",
    "# region class Account, Pair, Server\n",
    "class Account:\n",
    "    def __init__(self, login, password, server):\n",
    "        self.login = login\n",
    "        self.password = password\n",
    "        self.server = server\n",
    "\n",
    "class Pair:\n",
    "    def __init__(self, symbol, timeframe):\n",
    "        self.symbol = symbol\n",
    "        self.timeframe = timeframe\n",
    "\n",
    "class Create_Server:\n",
    "    def __init__(self, driver, server, username, password, db_name):\n",
    "        self.driver = driver\n",
    "        self.server = server\n",
    "        self.username = username\n",
    "        self.password = password\n",
    "        self.db_name =db_name\n",
    "# endregion\n",
    "\n",
    "# region variables\n",
    "# Define the connection parameters for SQL Server\n",
    "server = 'HUNG-LAPTOP' \n",
    "username = 'trading'  \n",
    "password = 'Dulieulon123'\n",
    "driver = '{ODBC Driver 17 for SQL Server}'\n",
    "driver_alchemy = 'ODBC+Driver+17+for+SQL+Server'\n",
    "db_name = \"audusd\"\n",
    "table_name = \"audusd_m15\"\n",
    "pair_name = \"AUDUSD.sml\"\n",
    "timeframe = mt5.TIMEFRAME_M15\n",
    "unique_text = 'text_id'\n",
    "from_day = pd.to_datetime(\"2000-01-01 00:00:00\")\n",
    "to_day = pd.to_datetime(\"2025-01-01 00:00:00\")\n",
    "chunk_capacity = 10000\n",
    "# endregion\n",
    "\n",
    "Server = Create_Server(driver, server, username, password, db_name)\n",
    "create_table(Server, table_name)\n",
    "\n",
    "# take data from OANDA MT5, split into smaller chunks for processing\n",
    "account = Account(6269482, 'jc6qhduy', 'OANDA-Demo-1')\n",
    "pair = Pair(pair_name, timeframe)\n",
    "date_ranges = generate_date_ranges(2000, 2025)\n",
    "ohlc_df = get_data_MT5(link, account, pair, from_day, to_day)\n",
    "print(\"number of rows from mt5: \", len(ohlc_df))\n",
    "df_chunk = divide_dataframe(ohlc_df, chunk_capacity)\n",
    "\n",
    "# add data to the table\n",
    "engine = create_engine(f\"mssql+pyodbc://{Server.username}:{Server.password}@{Server.server}/{Server.db_name}?driver={driver_alchemy}\")\n",
    "add_data(table_name, engine, df_chunk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tvDatafeed.main:error while signin\n",
      "WARNING:tvDatafeed.main:you are using nologin method, data you access may be limited\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              symbol    open    high     low   close  volume\n",
      "datetime                                                                    \n",
      "2024-12-23 06:00:00  OANDA:SPX500USD  5974.8  5975.0  5973.6  5973.6     9.0\n",
      "2024-12-23 06:01:00  OANDA:SPX500USD  5973.6  5976.6  5973.0  5976.6   157.0\n",
      "2024-12-23 06:02:00  OANDA:SPX500USD  5977.2  5979.2  5975.6  5977.6   167.0\n",
      "2024-12-23 06:03:00  OANDA:SPX500USD  5978.0  5979.4  5977.2  5978.0    75.0\n",
      "2024-12-23 06:04:00  OANDA:SPX500USD  5977.8  5977.8  5974.0  5976.4    84.0\n",
      "...                              ...     ...     ...     ...     ...     ...\n",
      "2024-12-31 17:19:00  OANDA:SPX500USD  5933.8  5934.4  5933.8  5934.2     9.0\n",
      "2024-12-31 17:20:00  OANDA:SPX500USD  5934.8  5935.2  5934.8  5935.0     6.0\n",
      "2024-12-31 17:21:00  OANDA:SPX500USD  5934.4  5935.2  5934.4  5935.2    15.0\n",
      "2024-12-31 17:22:00  OANDA:SPX500USD  5935.2  5935.2  5935.0  5935.2    10.0\n",
      "2024-12-31 17:23:00  OANDA:SPX500USD  5935.0  5935.0  5935.0  5935.0     1.0\n",
      "\n",
      "[7218 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "from tvDatafeed import TvDatafeed, Interval\n",
    "\n",
    "# Initialize TvDatafeed with your TradingView username and password\n",
    "username = 'ngdanghung2000@gmail.com'\n",
    "password = 'Matkhaumoi123!'\n",
    "\n",
    "for i in (1,30):\n",
    "    tv = TvDatafeed(username, password)\n",
    "\n",
    "    # Download historical data for a specific symbol\n",
    "    symbol = 'SPX500USD'\n",
    "    exchange = 'OANDA'\n",
    "    interval = Interval.in_1_minute\n",
    "    n_bars = 10000\n",
    "    data = tv.get_hist(symbol, exchange, interval, n_bars)\n",
    "\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GET DATA FROM SQL, we have to split the data into smaller chunks to prevent memory allocate error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id       time    open    high     low  close  tick_volume  spread  \\\n",
      "0   1 2000-01-03  0.6563  0.6574  0.6563  0.657           11      50   \n",
      "\n",
      "            text_id  \n",
      "0  2000-01-03-00-00  \n"
     ]
    }
   ],
   "source": [
    "# GET DATA FROM SQL\n",
    "# region import\n",
    "import pyodbc\n",
    "import pandas as pd\n",
    "import MetaTrader5 as mt5\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Define the connection parameters for SQL Server\n",
    "server = 'HUNG-LAPTOP' \n",
    "username = 'trading'  \n",
    "password = 'Dulieulon123'\n",
    "driver = '{ODBC Driver 17 for SQL Server}'\n",
    "driver_alchemy = 'ODBC+Driver+17+for+SQL+Server'\n",
    "db_name = \"audusd\"\n",
    "table_name = \"audusd_m15\"\n",
    "pair_name = \"AUDUSD.sml\"\n",
    "timeframe = mt5.TIMEFRAME_M15\n",
    "unique_text = 'text_id'\n",
    "from_day = pd.to_datetime(\"2000-01-01 00:00:00\")\n",
    "to_day = pd.to_datetime(\"2025-01-01 00:00:00\")\n",
    "chunk_capacity = 50000\n",
    "# endregion\n",
    "\n",
    "class Create_Server:\n",
    "    def __init__(self, driver, server, username, password, db_name):\n",
    "        self.driver = driver\n",
    "        self.server = server\n",
    "        self.username = username\n",
    "        self.password = password\n",
    "        self.db_name =db_name\n",
    "Server = Create_Server(driver, server, username, password, db_name)\n",
    "\n",
    "# Create the SQLAlchemy engine\n",
    "engine = create_engine(f\"mssql+pyodbc://{Server.username}:{Server.password}@{Server.server}/{Server.db_name}?driver={driver_alchemy}\")\n",
    "\n",
    "# Define the query to fetch data from the table `audusd_m15`\n",
    "query = f\"SELECT * FROM {table_name}\"\n",
    "\n",
    "# Specify the chunk size\n",
    "chunk_size = 100000  # Adjust this based on your memory limits\n",
    "\n",
    "# Read the data in chunks\n",
    "chunk_iter = pd.read_sql_query(query, engine, chunksize=chunk_size)\n",
    "\n",
    "# Initialize an empty list to store each chunk\n",
    "chunks = []\n",
    "\n",
    "# Process each chunk\n",
    "for chunk in chunk_iter:\n",
    "    # Perform any necessary data processing on the chunk here\n",
    "    chunks.append(chunk)\n",
    "\n",
    "# Concatenate all chunks into a single DataFrame\n",
    "df = pd.concat(chunks, ignore_index=True)\n",
    "\n",
    "# Now you can work with your DataFrame `df`\n",
    "print(df.head(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ,  audusd_m1\n",
      "2 ,  audusd_m2\n",
      "3 ,  audusd_m3\n",
      "4 ,  audusd_m4\n",
      "5 ,  audusd_m5\n",
      "10 ,  audusd_m10\n",
      "15 ,  audusd_m15\n",
      "30 ,  audusd_m30\n",
      "16385 ,  audusd_h1\n",
      "16386 ,  audusd_h2\n",
      "16387 ,  audusd_h3\n",
      "16388 ,  audusd_h4\n",
      "16390 ,  audusd_h6\n",
      "16408 ,  audusd_d1\n",
      "32769 ,  audusd_w1\n",
      "49153 ,  audusd_mn1\n"
     ]
    }
   ],
   "source": [
    "import MetaTrader5 as mt5\n",
    "import pandas as pd\n",
    "\n",
    "timeframe_list = [mt5.TIMEFRAME_M1, mt5.TIMEFRAME_M2, mt5.TIMEFRAME_M3, mt5.TIMEFRAME_M4,\n",
    "                  mt5.TIMEFRAME_M5, mt5.TIMEFRAME_M10, mt5.TIMEFRAME_M15,\n",
    "                  mt5.TIMEFRAME_M30, mt5.TIMEFRAME_H1, mt5.TIMEFRAME_H2,\n",
    "                  mt5.TIMEFRAME_H3, mt5.TIMEFRAME_H4, mt5.TIMEFRAME_H6, mt5.TIMEFRAME_D1, \n",
    "                  mt5.TIMEFRAME_W1, mt5.TIMEFRAME_MN1]\n",
    "\n",
    "prefix = \"audusd\"\n",
    "table_name_list = [f\"{prefix}_m1\", f\"{prefix}_m2\", f\"{prefix}_m3\", f\"{prefix}_m4\",\n",
    "                   f\"{prefix}_m5\", f\"{prefix}_m10\", f\"{prefix}_m15\",\n",
    "                   f\"{prefix}_m30\", f\"{prefix}_h1\", f\"{prefix}_h2\",\n",
    "                   f\"{prefix}_h3\", f\"{prefix}_h4\", f\"{prefix}_h6\", f\"{prefix}_d1\", \n",
    "                   f\"{prefix}_w1\", f\"{prefix}_mn1\"]\n",
    "\n",
    "\n",
    "# Create a dictionary with the two lists\n",
    "data = {\n",
    "    \"Timeframe\": timeframe_list,\n",
    "    \"Table Name\": table_name_list\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df_id = pd.DataFrame(data)\n",
    "\n",
    "for index, row in df_id.iterrows():\n",
    "    print(row['Timeframe'], \", \", row['Table Name'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
